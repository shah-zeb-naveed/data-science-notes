{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4eh9I3LsGcy1XySIZyd4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/data-science-notes/blob/main/interview_systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cache"
      ],
      "metadata": {
        "id": "mWemi3_cVOes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lru_cache.py\n",
        "import sys\n",
        "import requests\n",
        "from collections import OrderedDict\n",
        "\n",
        "class ImageCache:\n",
        "    def __init__(self, max_size_bytes):\n",
        "        self.max_size = max_size_bytes\n",
        "        self.cache = OrderedDict()\n",
        "        self.current_size = 0\n",
        "\n",
        "    def get(self, url):\n",
        "        if url in self.cache:\n",
        "            # Move to end to mark as recently used\n",
        "            self.cache.move_to_end(url)\n",
        "            return f\"Cache Hit: {url}\"\n",
        "        else:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                response.raise_for_status()\n",
        "                image_bytes = response.content\n",
        "                image_size = len(image_bytes)\n",
        "\n",
        "                # If image is too big to cache, skip caching\n",
        "                if image_size > self.max_size:\n",
        "                    return f\"Too big. Downloaded (Not Cached): {url}\"\n",
        "\n",
        "                # Evict least recently used items until there's space\n",
        "                while self.current_size + image_size > self.max_size and self.cache:\n",
        "                    _, old_bytes = self.cache.popitem(last=False) # first added\n",
        "                    self.current_size -= len(old_bytes)\n",
        "\n",
        "                self.cache[url] = image_bytes\n",
        "                self.current_size += image_size\n",
        "                return f\"Downloaded and Cached: {url}\"\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                return f\"Error downloading image: {e}\"\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"Usage: python script.py <input_file>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # read fome file\n",
        "    # input_file = sys.argv[1]\n",
        "    # with open(input_file, 'r') as f:\n",
        "    #     lines = f.read().splitlines()\n",
        "\n",
        "    # max_size = int(lines[0])\n",
        "    # num_urls = int(lines[1])\n",
        "    # urls = lines[2:]\n",
        "\n",
        "    # read from command line\n",
        "    max_size = int(sys.argv[1])\n",
        "    num_urls = int(sys.argv[2])\n",
        "    urls = sys.argv[3:]\n",
        "\n",
        "    cache = ImageCache(max_size)\n",
        "\n",
        "    for url in urls:\n",
        "        result = cache.get(url)\n",
        "        print(result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aZ72Rp4-10C",
        "outputId": "e08ec68f-4697-4414-b11a-3d634809fada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lru_cache.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python lru_cache.py 10000 3 https://placehold.co/600x400.png https://placehold.co/600x400.png https://placehold.co/600x400.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzmeuD_u_zy_",
        "outputId": "4cf182a0-2239-46d6-a4fd-83cd3347db97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and Cached: https://placehold.co/600x400.png\n",
            "Cache Hit: https://placehold.co/600x400.png\n",
            "Cache Hit: https://placehold.co/600x400.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min({2:'A',1:'B'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBCZEJvAKI7s",
        "outputId": "2b749de5-f8ae-4b51-da1a-aa679e30a3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile advanced_lru_cache.py\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "#import threading\n",
        "import time\n",
        "import pickle\n",
        "from collections import OrderedDict, defaultdict, deque\n",
        "from urllib.parse import urlparse\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from heapq import heappush, heappop\n",
        "\n",
        "\n",
        "\n",
        "class CacheItem:\n",
        "    def __init__(self, url, content, size, timestamp, priority=0):\n",
        "        self.url = url\n",
        "        self.content = content\n",
        "        self.size = size\n",
        "        self.last_access = timestamp\n",
        "        self.access_count = 1\n",
        "        self.insert_time = timestamp\n",
        "        self.priority = priority\n",
        "        self.ttl_expiry = timestamp + 300  # default TTL of 5 minutes\n",
        "        self.lfu_heap = []  # minheap for LFU\n",
        "        self.fifo_queue = deque()  # for FIFO\n",
        "\n",
        "\n",
        "class ImageCache:\n",
        "    def __init__(self, max_size_bytes, eviction_policy=\"FIFO\", max_item_size=10_000_000, bandwidth_limit=5, snapshot_file=\"cache_snapshot.pkl\"):\n",
        "        self.max_size = max_size_bytes\n",
        "        self.max_item_size = max_item_size\n",
        "\n",
        "        self.size = 0\n",
        "#        self.lock = threading.RLock()\n",
        "        self.eviction_policy = eviction_policy\n",
        "\n",
        "        self.bandwidth_limit = bandwidth_limit  # max downloads per minute\n",
        "        self.snapshot_file = snapshot_file\n",
        "\n",
        "        self.cache = OrderedDict()\n",
        "        self.download_timestamps = deque()\n",
        "        self.load_snapshot()\n",
        "\n",
        "    def save_snapshot(self):\n",
        "        with open(self.snapshot_file, 'wb') as f:\n",
        "            pickle.dump(self.cache, f)\n",
        "\n",
        "    def load_snapshot(self):\n",
        "        if os.path.exists(self.snapshot_file):\n",
        "            with open(self.snapshot_file, 'rb') as f:\n",
        "                self.cache = pickle.load(f)\n",
        "                self.size = sum(item.size for item in self.cache.values())\n",
        "\n",
        "    def _evict(self):\n",
        "\n",
        "        # optimization\n",
        "        if self.eviction_policy == \"LFU\":\n",
        "            while self.lfu_heap:\n",
        "                # insert_time not used but can be used for breaking ties\n",
        "                access_count_at_push, _, url = heappop(self.lfu_heap)\n",
        "                if url in self.cache:\n",
        "                    item = self.cache[url]\n",
        "                    # not stale if access_counts match\n",
        "                    if item.access_count == access_count_at_push:\n",
        "                        del self.cache[url]\n",
        "                        self.size -= item.size\n",
        "                        break  # valid eviction\n",
        "\n",
        "        # practically, this is the same as ordereddict I think\n",
        "        elif self.eviction_policy == \"FIFO\":\n",
        "            while self.fifo_queue:\n",
        "                url = self.fifo_queue.popleft()\n",
        "                # evicted URLs can stay in queue so check this\n",
        "                if url in self.cache:\n",
        "                    item = self.cache.pop(url)\n",
        "                    self.size -= item.size\n",
        "                    break  # evicted\n",
        "\n",
        "        if self.eviction_policy == \"LRU\":\n",
        "            url, item = self.cache.popitem(last=False)\n",
        "        elif self.eviction_policy == \"FIFO\":\n",
        "            url = next(iter(self.cache))\n",
        "            item = self.cache.pop(url)\n",
        "        elif self.eviction_policy == \"LFU\":\n",
        "            url = min(self.cache, key=lambda k: self.cache[k].access_count)\n",
        "            item = self.cache.pop(url)\n",
        "\n",
        "        elif self.eviction_policy == \"PRIORITY\":\n",
        "            url = min(self.cache, key=lambda k: self.cache[k].priority)\n",
        "            item = self.cache.pop(url)\n",
        "        else:\n",
        "            # default\n",
        "            url, item = self.cache.popitem(last=False)\n",
        "\n",
        "        self.size -= item.size\n",
        "\n",
        "    def _is_bandwidth_limited(self):\n",
        "        now = time.time()\n",
        "        # remove timestamps older than 1 minute\n",
        "        if self.download_timestamps:\n",
        "          diff  = now - self.download_timestamps[0]\n",
        "          #print('diff:', diff)\n",
        "\n",
        "        # bandiwth measured per minute so remove any old before calculating numerator\n",
        "        while self.download_timestamps and now - self.download_timestamps[0] > 60:\n",
        "            self.download_timestamps.popleft()\n",
        "\n",
        "        requests_per_minute = len(self.download_timestamps) + 1 # this current\n",
        "        print('requests_per_minute:', requests_per_minute)\n",
        "        return requests_per_minute > self.bandwidth_limit\n",
        "\n",
        "    def _download(self, url):\n",
        "        if self._is_bandwidth_limited():\n",
        "            raise Exception(f\"Bandwidth limit exceeded. Try again later.\")\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            response.raise_for_status()\n",
        "            content = response.content\n",
        "            if len(content) > self.max_item_size:\n",
        "                return f\"Image too large to cache: {url}\"\n",
        "            self.download_timestamps.append(time.time())\n",
        "            return content\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"Error downloading image: {e}\"\n",
        "\n",
        "    def get(self, url):\n",
        "        #with self.lock:\n",
        "          now = time.time()\n",
        "\n",
        "          # Clean expired items\n",
        "          # Eviction is a separate process than this\n",
        "          expired = [key for key, item in self.cache.items() if now > item.ttl_expiry]\n",
        "          for key in expired:\n",
        "              self.size -= self.cache[key].size\n",
        "              del self.cache[key]\n",
        "\n",
        "          if url in self.cache:\n",
        "              item = self.cache[url]\n",
        "              item.last_access = now\n",
        "              item.access_count += 1\n",
        "              # Only move to end if we're using LRU policy\n",
        "              if self.eviction_policy == \"LRU\":\n",
        "                  self.cache.move_to_end(url)\n",
        "\n",
        "              # Also inside get(), after item.access_count += 1, if LFU, push updated count\n",
        "              if self.eviction_policy == \"LFU\":\n",
        "                  heappush(self.lfu_heap, (item.access_count, item.insert_time, url))\n",
        "\n",
        "              return f\"CACHE HIT: {url}\"\n",
        "\n",
        "          result = self._download(url)\n",
        "\n",
        "          image_size = len(result)\n",
        "          if image_size > self.max_size:\n",
        "              return f\"Image exceeds total cache size: {url}\"\n",
        "\n",
        "          while self.size + image_size > self.max_size:\n",
        "              self._evict()\n",
        "\n",
        "          new_item = CacheItem(url, result, image_size, now)\n",
        "          self.cache[url] = new_item\n",
        "          self.size += image_size\n",
        "\n",
        "          # optimizaiton\n",
        "          if self.eviction_policy == \"LFU\":\n",
        "              heappush(self.lfu_heap, (new_item.access_count + 1, new_item.insert_time, url))\n",
        "          elif self.eviction_policy == \"FIFO\":\n",
        "              self.fifo_queue.append(url)\n",
        "\n",
        "          return f\"DOWNLOADED: {url}\"\n",
        "\n",
        "    def prefetch(self, urls):\n",
        "        for url in urls:\n",
        "            #threading.Thread(target=self.get, args=(url,)).start()\n",
        "            self.get(url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) != 2:\n",
        "        print(\"Usage: python image_cache.py <input_file>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    input_file = sys.argv[1]\n",
        "\n",
        "    with open(input_file, 'r') as f:\n",
        "        max_cache_size = int(f.readline().strip())\n",
        "        n = int(f.readline().strip())\n",
        "        urls = [f.readline().strip() for _ in range(n)]\n",
        "\n",
        "    cache = ImageCache(max_cache_size, eviction_policy=\"FIFO\")\n",
        "    for url in urls:\n",
        "        print('---')\n",
        "        print(url)\n",
        "        result = cache.get(url)\n",
        "        print(result)\n",
        "        #time.sleep(5)\n",
        "\n",
        "    cache.get(\"https://placehold.co/600x400/EEE/31343C?font=poppins&text=Poppins\")\n",
        "\n",
        "    print('===')\n",
        "    # Example of prefetching (next likely images)\n",
        "    #cache.prefetch([\"https://placehold.co/600x400/EEE/31343C?font=poppins&text=Poppins\"])\n",
        "\n",
        "    # Save snapshot at the end\n",
        "    #cache.save_snapshot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jEtfqXNFjaq",
        "outputId": "341c3cac-c8c0-485d-f6f2-4087b0bb9d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting advanced_lru_cache.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile input.txt\n",
        "10000\n",
        "3\n",
        "https://placehold.co/600x400.png\n",
        "https://placehold.co/600x400.png\n",
        "https://placehold.co/150x150.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u43yvLlFr0U",
        "outputId": "2dbca283-3aa9-4d2f-f85d-bebab1a3f804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python advanced_lru_cache.py input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsMjpIpoFjSq",
        "outputId": "952bf898-ac5c-4be0-ef5a-279b412350f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "https://placehold.co/600x400.png\n",
            "requests_per_minute: 1\n",
            "DOWNLOADED: https://placehold.co/600x400.png\n",
            "---\n",
            "https://placehold.co/600x400.png\n",
            "CACHE HIT: https://placehold.co/600x400.png\n",
            "---\n",
            "https://placehold.co/150x150.png\n",
            "requests_per_minute: 2\n",
            "DOWNLOADED: https://placehold.co/150x150.png\n",
            "requests_per_minute: 3\n",
            "===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature                   | Heap-Based LFU                     | `min()` on `OrderedDict` LFU              |\n",
        "| ------------------------- | ---------------------------------- | ----------------------------------------- |\n",
        "| **Eviction Time**         | **O(log n)** (heap push/pop)       | **O(n)** (`min()` over all items)         |\n",
        "| **Access Time (get/put)** | O(1) + heap push = O(log n)        | O(1) + O(1) update + O(n) min at eviction |\n",
        "| **Space Overhead**        | O(n) for `cache`, O(n) for `heap`  | O(n) for `cache` only                     |\n",
        "| **Pros**                  | Fast eviction                      | Simpler implementation                    |\n",
        "| **Cons**                  | More memory and stale heap entries | Slower eviction due to full scan          |\n"
      ],
      "metadata": {
        "id": "zLB51-DPR1F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature            | Deque-Based FIFO                    | `OrderedDict` FIFO                 |\n",
        "| ------------------ | ----------------------------------- | ---------------------------------- |\n",
        "| **Eviction Time**  | O(1) with stale-check (amortized)   | **O(1)** via `popitem(last=False)` |\n",
        "| **Access Time**    | O(1) + stale cleanup                | **O(1)**                           |\n",
        "| **Space Overhead** | O(n) for `cache` + O(n) for `deque` | O(n) for single `OrderedDict`      |\n",
        "| **Pros**           | Explicit queue logic, flexible      | Cleanest and most efficient        |\n",
        "| **Cons**           | Potential stale entries             | Less customizable                  |\n"
      ],
      "metadata": {
        "id": "SWF_XDNWR3uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Policy   | Best for Performance | Best for Simplicity |\n",
        "| -------- | -------------------- | ------------------- |\n",
        "| **LFU**  | Heap-based           | `min()` + `dict`    |\n",
        "| **FIFO** | `OrderedDict`        | `OrderedDict`       |\n"
      ],
      "metadata": {
        "id": "qLw2ONHAR5Dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Strategy**                         | **Pros**                                                                 | **Cons**                                                       | **Use Cases**                                                                    |\n",
        "| ------------------------------------ | ------------------------------------------------------------------------ | -------------------------------------------------------------- | -------------------------------------------------------------------------------- |\n",
        "| **LRU (Least Recently Used)**        | Simple and efficient eviction of least recently accessed items           | Poor for workloads with frequent full scans or cyclic patterns | Browser caches, database buffers, in-memory caches (e.g., `functools.lru_cache`) |\n",
        "| **LFU (Least Frequently Used)**      | Retains hot items accessed repeatedly, good for skewed access patterns   | Requires frequency tracking; may retain stale \"popular\" items  | CDN edge caches, recommendation systems                                          |\n",
        "| **FIFO (First In First Out)**        | Simple and predictable                                                   | Ignores access pattern; may evict useful items                 | Streaming data, write-behind caches                                              |\n",
        "| **Random Replacement**               | Low-overhead eviction                                                    | Non-deterministic; can evict hot items                         | Hardware caches (e.g., CPU), when memory is tight                                |\n",
        "| **TTL (Time to Live)**               | Auto-purges stale items after a time threshold                           | Fixed expiration may evict still-useful items                  | DNS caching, session tokens                                                      |\n",
        "| **ARC (Adaptive Replacement Cache)** | Balances between LRU and LFU adaptively                                  | Complex to implement                                           | Filesystem page caching (ZFS, IBM DB2)                                           |\n",
        "| **MRU (Most Recently Used)**         | Good for patterns where recently used items are less likely to be reused | Counterintuitive for many apps; rarely used alone              | Specific DB workloads (e.g., full table scans), specialized memory pools         |\n",
        "| **2Q Cache**                         | Improves LRU by filtering out short-lived entries                        | Slightly more complex than LRU                                 | Web servers, virtual memory systems                                              |\n",
        "| **Segmented LRU**                    | Prevents cache pollution from one workload segment                       | Needs workload classification                                  | JVM memory pools, multi-tenant environments                                      |\n"
      ],
      "metadata": {
        "id": "XbvYuwlHSnV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Memory DB"
      ],
      "metadata": {
        "id": "rrVnKbVXVK9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mem_db.py\n",
        "\n",
        "from sortedcontainers import SortedDict\n",
        "from typing import Any, Optional\n",
        "import time\n",
        "\n",
        "class InMemoryDatabase:\n",
        "    def __init__(self):\n",
        "        # Primary key-value store\n",
        "        self.store = dict()\n",
        "\n",
        "        # Secondary index: sorted by key\n",
        "        self.sorted_keys = SortedDict()\n",
        "\n",
        "        # Timestamp index: maps timestamp -> key\n",
        "        self.timestamp_index = SortedDict()\n",
        "\n",
        "    def put(self, key: Any, value: Any, timestamp: Optional[float] = None):\n",
        "        \"\"\"Insert or update a key with value and optional timestamp.\"\"\"\n",
        "        self.store[key] = value\n",
        "        self.sorted_keys[key] = value\n",
        "\n",
        "        ts = timestamp if timestamp is not None else time.time()\n",
        "        self.timestamp_index[ts] = key\n",
        "\n",
        "    def get(self, key: Any) -> Optional[Any]:\n",
        "        \"\"\"Get value for a key.\"\"\"\n",
        "        return self.store.get(key)\n",
        "\n",
        "    def delete(self, key: Any):\n",
        "        \"\"\"Delete key from database.\"\"\"\n",
        "        if key in self.store:\n",
        "            del self.store[key]\n",
        "        if key in self.sorted_keys:\n",
        "            del self.sorted_keys[key]\n",
        "\n",
        "        # Remove from timestamp index\n",
        "        to_remove = [ts for ts, k in self.timestamp_index.items() if k == key]\n",
        "        for ts in to_remove:\n",
        "            del self.timestamp_index[ts]\n",
        "\n",
        "    def get_range(self, start_key: Any, end_key: Any) -> dict:\n",
        "        \"\"\"Get all key-value pairs within the key range [start_key, end_key).\"\"\"\n",
        "        keys = [k for k in self.sorted_keys.irange(start_key, end_key)]\n",
        "        return {k: self.store[k] for k in keys}\n",
        "\n",
        "    def get_by_time_range(self, start_time: float, end_time: float) -> dict:\n",
        "        \"\"\"Return key-value pairs inserted in a given time range.\"\"\"\n",
        "        result = {}\n",
        "        for ts in self.timestamp_index.irange(start_time, end_time):\n",
        "            key = self.timestamp_index[ts]\n",
        "            if key in self.store:\n",
        "                result[key] = self.store[key]\n",
        "        return result\n",
        "\n",
        "    def dump(self) -> dict:\n",
        "        \"\"\"Return all key-value pairs.\"\"\"\n",
        "        return dict(self.store)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    db = InMemoryDatabase()\n",
        "    db.put(\"a\", 1)\n",
        "    time.sleep(0.1)\n",
        "    db.put(\"b\", 2)\n",
        "    time.sleep(0.1)\n",
        "    db.put(\"c\", 3)\n",
        "    time.sleep(1)\n",
        "    db.put(\"d\", 5)\n",
        "\n",
        "    print(\"Get b:\", db.get(\"b\"))\n",
        "    print(\"Range a to c:\", db.get_range(\"a\", \"c\"))\n",
        "\n",
        "    print(\"Time range:\", db.get_by_time_range(time.time() - 1, time.time()))\n",
        "    db.delete(\"b\")\n",
        "    print(\"After delete b:\", db.dump())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlAhb-GSTSZM",
        "outputId": "dc606f98-22fe-487c-db7c-53cd4911505d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mem_db.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python mem_db.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDgM8vv6TSVv",
        "outputId": "064fd58e-f958-4beb-bec2-263440e53c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get b: 2\n",
            "Range a to c: {'a': 1, 'b': 2, 'c': 3}\n",
            "Time range: {'d': 5}\n",
            "After delete b: {'a': 1, 'c': 3, 'd': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# without sortedcontainer, using bisect. bisect insert is still O(n)\n",
        "# unlike sortedcontainers which used a balanced tree data structure\n",
        "\n",
        "import bisect\n",
        "\n",
        "class ManualSortedDict:\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "        # extra list that's always maintained sorted\n",
        "        self.sorted_keys = []\n",
        "\n",
        "    def put(self, key, value):\n",
        "        if key not in self.store:\n",
        "            bisect.insort(self.sorted_keys, key)\n",
        "        self.store[key] = value\n",
        "\n",
        "    def get(self, key):\n",
        "        return self.store.get(key)\n",
        "\n",
        "    def delete(self, key):\n",
        "        if key in self.store:\n",
        "            self.sorted_keys.remove(key)\n",
        "            del self.store[key]\n",
        "\n",
        "    def get_range(self, start, end):\n",
        "        start_idx = bisect.bisect_left(self.sorted_keys, start)\n",
        "        end_idx = bisect.bisect_left(self.sorted_keys, end)\n",
        "        return {\n",
        "            k: self.store[k]\n",
        "            for k in self.sorted_keys[start_idx:end_idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "buj-yUjETSTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualSortedDict:\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "        self.sorted_keys = []\n",
        "        self.sorted_timestamps = []  # list of (timestamp, key) tuples\n",
        "\n",
        "    def insert_sorted(self, key):\n",
        "        low, high = 0, len(self.sorted_keys)\n",
        "        while low < high:\n",
        "            mid = (low + high) // 2\n",
        "            if self.sorted_keys[mid] < key:\n",
        "                low = mid + 1 # definitely not the right place\n",
        "            else:\n",
        "                high = mid\n",
        "        self.sorted_keys.insert(low, key)\n",
        "\n",
        "    def insert_sorted_timestamp(self, timestamp, key):\n",
        "        low, high = 0, len(self.sorted_timestamps)\n",
        "        while low < high:\n",
        "            mid = (low + high) // 2\n",
        "            if self.sorted_timestamps[mid][0] < timestamp:\n",
        "                low = mid + 1\n",
        "            else:\n",
        "                high = mid\n",
        "        self.sorted_timestamps.insert(low, (timestamp, key))\n",
        "\n",
        "    def put(self, key, value, timestamp):\n",
        "        if key not in self.store:\n",
        "            self.insert_sorted(key)\n",
        "            self.insert_sorted_timestamp(timestamp, key)\n",
        "        else:\n",
        "            # remove old timestamp entry and insert new one\n",
        "            old_ts, _ = self.store[key]\n",
        "            self.sorted_timestamps.remove((old_ts, key))\n",
        "            self.insert_sorted_timestamp(timestamp, key)\n",
        "        self.store[key] = (timestamp, value)\n",
        "\n",
        "    def get(self, key):\n",
        "        item = self.store.get(key)\n",
        "        return item[1] if item else None\n",
        "\n",
        "    def delete(self, key):\n",
        "        if key in self.store:\n",
        "            self.sorted_keys.remove(key)\n",
        "            ts, _ = self.store[key]\n",
        "            self.sorted_timestamps.remove((ts, key))\n",
        "            del self.store[key]\n",
        "\n",
        "    def get_range(self, start, end):\n",
        "        start_idx = self.binary_search(self.sorted_keys, start)\n",
        "        end_idx = self.binary_search(self.sorted_keys, end)\n",
        "        return {\n",
        "            k: self.store[k][1]\n",
        "            for k in self.sorted_keys[start_idx:end_idx]\n",
        "        }\n",
        "\n",
        "    def get_range_by_time(self, start_ts, end_ts):\n",
        "        start_idx = self.binary_search_ts(start_ts)\n",
        "        end_idx = self.binary_search_ts(end_ts)\n",
        "        keys_in_range = [k for ts, k in self.sorted_timestamps[start_idx:end_idx]]\n",
        "        return {\n",
        "            k: self.store[k][1] for k in keys_in_range\n",
        "        }\n",
        "\n",
        "    def binary_search(self, arr, key):\n",
        "        low, high = 0, len(arr)\n",
        "        while low < high:\n",
        "            mid = (low + high) // 2\n",
        "            if arr[mid] < key:\n",
        "                low = mid + 1\n",
        "            else:\n",
        "                high = mid\n",
        "        return low\n",
        "\n",
        "    def binary_search_ts(self, timestamp):\n",
        "        low, high = 0, len(self.sorted_timestamps)\n",
        "        while low < high:\n",
        "            mid = (low + high) // 2\n",
        "            if self.sorted_timestamps[mid][0] < timestamp:\n",
        "                low = mid + 1\n",
        "            else:\n",
        "                high = mid\n",
        "        return low\n"
      ],
      "metadata": {
        "id": "R8whpm-ATSQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ],
      "metadata": {
        "id": "TVLsOIsbVBya"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syEXulONVDOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For NLP stuff, https://github.com/shah-zeb-naveed/nlp/blob/main/nlp_pre_interview_refresher.ipynb"
      ],
      "metadata": {
        "id": "QK9t6QnFVDmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile word_counter.py\n",
        "\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "\n",
        "def word_count(file_path):\n",
        "    counts = defaultdict(int)\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            for word in line.strip().split():\n",
        "                counts[word] += 1\n",
        "\n",
        "    for word in sorted(counts):\n",
        "        print(f\"{word} {counts[word]}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) < 2:\n",
        "        print(\"Usage: python word_counter.py <input_file>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    word_count(sys.argv[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2ILT-H-_058",
        "outputId": "52f5728e-3fe5-4e8f-8c6e-8c718c3dd7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing word_counter.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile input.txt\n",
        "apple banana apple\n",
        "orange apple banana"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqi2tDvPCMct",
        "outputId": "9e8cbb05-5954-429b-c818-3651602f5e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python word_counter.py input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ryWpHHjCHw_",
        "outputId": "8f5155cd-9d0b-4532-d017-741bf5fe23d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple 3\n",
            "banana 2\n",
            "orange 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File I/O"
      ],
      "metadata": {
        "id": "MeYafoodU_KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a short snippet that writes into csv file and then reads it back\n",
        "\n",
        "import csv\n",
        "\n",
        "def write_and_read_csv(filename, data):\n",
        "    # Write data to CSV file\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerows(data)\n",
        "\n",
        "def csv_reader(csvfile):\n",
        "    # Read data from CSV file\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        read_data = list(reader)\n",
        "\n",
        "    return read_data\n",
        "\n",
        "\n",
        "# Example usage\n",
        "data = [\n",
        "    [\"Name\", \"Age\", \"City\"],\n",
        "    [\"Alice\", \"25\", \"New York\"],\n",
        "    [\"Bob\", \"30\", \"Los Angeles\"],\n",
        "    [\"Charlie\", \"28\", \"Chicago\"]\n",
        "]\n",
        "\n",
        "filename = \"example.csv\"\n",
        "read_data = write_and_read_csv(filename, data)\n",
        "print(csv_reader(filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlimylDmCaIm",
        "outputId": "1f84ef0d-0097-4e7c-c1a1-8f95fa68ad1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Name', 'Age', 'City'], ['Alice', '25', 'New York'], ['Bob', '30', 'Los Angeles'], ['Charlie', '28', 'Chicago']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log Processing"
      ],
      "metadata": {
        "id": "MzcW87cKU8JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "\n",
        "class LogParser:\n",
        "    def __init__(self, log_file_path):\n",
        "        self.log_file_path = log_file_path\n",
        "        self.entries = []\n",
        "        self._parse_log()\n",
        "\n",
        "    def _parse_log(self):\n",
        "        log_pattern = re.compile(r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+(?P<level>[A-Z]+)\\s+(?P<message>.+)')\n",
        "        with open(self.log_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                match_ = log_pattern.match(line.strip())\n",
        "                if match_:\n",
        "                    ts = datetime.strptime(match_.group('timestamp'), \"%Y-%m-%d %H:%M:%S\")\n",
        "                    self.entries.append({\n",
        "                        'timestamp': ts,\n",
        "                        'level': match_.group('level'),\n",
        "                        'message': match_.group('message')\n",
        "                    })\n",
        "\n",
        "    def filter(self, level=None, keyword=None, start=None, end=None):\n",
        "        result = self.entries\n",
        "        if level:\n",
        "            result = [entry for entry in result if entry['level'] == level]\n",
        "        if keyword:\n",
        "            result = [entry for entry in result if keyword in entry['message']]\n",
        "        if start:\n",
        "            result = [entry for entry in result if entry['timestamp'] >= start]\n",
        "        if end:\n",
        "            result = [entry for entry in result if entry['timestamp'] <= end]\n",
        "        return result\n",
        "\n",
        "    def count_errors_per_hour(self):\n",
        "        hourly_counts = defaultdict(int)\n",
        "        for entry in self.entries:\n",
        "            if entry['level'] == 'ERROR':\n",
        "                hour = entry['timestamp'].replace(minute=0, second=0, microsecond=0)\n",
        "                hourly_counts[hour] += 1\n",
        "        return dict(hourly_counts)\n"
      ],
      "metadata": {
        "id": "fWTWRRQ8DB67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.log\n",
        "2025-05-11 08:00:01 INFO Starting server on port 8080\n",
        "2025-05-11 08:01:15 WARN Memory usage is high\n",
        "2025-05-11 08:15:42 ERROR Failed to connect to database\n",
        "2025-05-11 08:45:12 INFO Health check passed\n",
        "2025-05-11 09:03:34 ERROR Timeout while processing request\n",
        "2025-05-11 09:15:01 INFO User login successful\n",
        "2025-05-11 10:00:00 ERROR Disk space low on /dev/sda1\n",
        "2025-05-11 10:05:23 WARN CPU temperature nearing threshold\n",
        "2025-05-11 10:45:11 INFO Request handled successfully\n",
        "2025-05-11 11:00:00 INFO Scheduled maintenance started\n",
        "2025-05-11 11:15:45 ERROR Backup process failed due to permissions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObwH29RnTjhH",
        "outputId": "3b0e9035-0c7d-4b29-a87d-eec89de8fe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing server.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "parser = LogParser('server.log')\n",
        "filtered = parser.filter(level='ERROR', keyword='timeout')\n",
        "errors_by_hour = parser.count_errors_per_hour()\n",
        "errors_by_hour"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "S7iMM4peTm2p",
        "outputId": "17b42dbb-71d8-4915-afc2-9b102ddcbd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'LogParser' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3168e52c8a9b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'server.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0merrors_by_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_errors_per_hour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0merrors_by_hour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LogParser' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Processing"
      ],
      "metadata": {
        "id": "EwbzE5mdU50b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from pyspark.sql import SparkSession\n",
        "    from pyspark.sql.types import *\n",
        "    import pyspark.sql.functions as F\n",
        "    SPARK_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SPARK_AVAILABLE = False\n",
        "    print(\"PySpark is not installed. Batch processing with Spark is not available.\")\n"
      ],
      "metadata": {
        "id": "xOeWzvl0YGcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample.csv\n",
        "id,name,age,salary,department\n",
        "1,Alice,30,70000,Engineering\n",
        "2,Bob,25,50000,Sales\n",
        "3,Charlie,35,80000,Engineering\n",
        "4,David,40,90000,HR\n",
        "5,Eve,28,55000,Marketing\n",
        "6,Frank,50,100000,Engineering\n",
        "7,Grace,22,45000,Sales\n",
        "8,Hannah,31,75000,Marketing\n",
        "9,Ian,29,52000,Engineering\n",
        "10,Jane,38,88000,HR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l1501PkabYP",
        "outputId": "0340e1af-f279-40b9-d5ec-13399c1fba36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sample.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = None\n",
        "if x is None:\n",
        "  print('s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYT-BHVfbDWL",
        "outputId": "28d0ec92-e200-4330-e6f4-b80267157066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchFileProcessor:\n",
        "    def __init__(self, filepath, batch_size=1000):\n",
        "        self.filepath = filepath\n",
        "        self.batch_size = batch_size\n",
        "        self.file_type = self._detect_file_type()\n",
        "\n",
        "    def _detect_file_type(self):\n",
        "        ext = os.path.splitext(self.filepath)[-1].lower()\n",
        "        return \"csv\" if ext == \".csv\" else \"text\"\n",
        "\n",
        "    def read_text_in_batches(self, filter_fn=None):\n",
        "        with open(self.filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            batch = []\n",
        "            for line in f:\n",
        "                if filter_fn is None or filter_fn(line): # smart\n",
        "                    batch.append(line.rstrip())\n",
        "                if len(batch) >= self.batch_size:\n",
        "                    yield batch\n",
        "                    batch = []\n",
        "            if batch:\n",
        "                yield batch\n",
        "\n",
        "    def read_csv_in_batches(self, filter_fn=None, usecols=None):\n",
        "        for chunk in pd.read_csv(self.filepath, chunksize=self.batch_size, usecols=usecols): # , skiprows=1, header=None\n",
        "            if filter_fn:\n",
        "                chunk = chunk[chunk.apply(filter_fn, axis=1)]\n",
        "            yield chunk\n",
        "\n",
        "    def read_with_spark(self, filter_expr=None, columns=None):\n",
        "        if not SPARK_AVAILABLE:\n",
        "            raise ImportError(\"PySpark is not installed.\")\n",
        "\n",
        "        spark = SparkSession.builder.getOrCreate()\n",
        "        df = spark.read.csv(self.filepath, header=True, inferSchema=True)\n",
        "        if columns:\n",
        "            df = df.select(columns)\n",
        "        if filter_expr:\n",
        "            df = df.filter(filter_expr)\n",
        "        return df\n",
        "\n",
        "    def process_batches(self, processor_fn, mode=\"text\", **kwargs):\n",
        "        if mode == \"text\":\n",
        "            for batch in self.read_text_in_batches(**kwargs):\n",
        "                processor_fn(batch)\n",
        "        elif mode == \"csv\":\n",
        "            for batch in self.read_csv_in_batches(**kwargs):\n",
        "                processor_fn(batch)\n",
        "                print('---')\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported mode: choose 'text' or 'csv'\")\n",
        "\n",
        "def filter_fn_error(line):\n",
        "    return \"INFO\" in line\n",
        "\n",
        "\n",
        "# custom processor function\n",
        "def processor_fn(batch):\n",
        "  if isinstance(batch, pd.DataFrame):\n",
        "    print(batch.shape)\n",
        "  else:\n",
        "    print(batch)\n",
        "\n",
        "bfp = BatchFileProcessor('server.log', batch_size=2)\n",
        "bfp.process_batches(processor_fn, mode=\"text\", filter_fn=filter_fn_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmY3t7svYEJS",
        "outputId": "b4d0639e-9af4-4f6e-b2bd-474ba0f8c68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2025-05-11 08:00:01 INFO Starting server on port 8080', '2025-05-11 08:45:12 INFO Health check passed']\n",
            "['2025-05-11 09:15:01 INFO User login successful', '2025-05-11 10:45:11 INFO Request handled successfully']\n",
            "['2025-05-11 11:00:00 INFO Scheduled maintenance started']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_fn_age(df):\n",
        "    return df['salary'] > 50000\n",
        "\n",
        "bfp = BatchFileProcessor('sample.csv', batch_size=2)\n",
        "bfp.process_batches(processor_fn, mode=\"csv\", filter_fn=filter_fn_age)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxdG67A6bMb4",
        "outputId": "fdf9bfb9-cba0-4acb-d6a3-1a40f88fd018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5)\n",
            "---\n",
            "(2, 5)\n",
            "---\n",
            "(2, 5)\n",
            "---\n",
            "(1, 5)\n",
            "---\n",
            "(2, 5)\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Step 1: Create and save large data to disk (once)\n",
        "X = np.random.rand(1_000_000, 20)\n",
        "y = np.random.rand(1_000_000)\n",
        "\n",
        "np.save('X.npy', X)\n",
        "np.save('y.npy', y)\n",
        "\n",
        "# Step 2: Load with memmap for batch processing\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_path, y_path = 'X.npy', 'y.npy'\n",
        "n_samples, n_features = 1_000_000, 20\n",
        "batch_size = 10000\n",
        "\n",
        "model = SGDRegressor()\n",
        "patience, wait = 3, 0\n",
        "min_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(50):\n",
        "    X_mem = np.memmap(X_path, dtype='float32', mode='r', shape=(n_samples, n_features))\n",
        "    y_mem = np.memmap(y_path, dtype='float32', mode='r', shape=(n_samples,))\n",
        "\n",
        "    for i in range(0, n_samples, batch_size):\n",
        "        X_batch = X_mem[i:i + batch_size]\n",
        "        y_batch = y_mem[i:i + batch_size]\n",
        "        mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
        "\n",
        "        # Filtered arrays\n",
        "        X_clean = X[mask]\n",
        "        y_clean = y[mask]\n",
        "\n",
        "        model.partial_fit(X_clean, y_clean)\n",
        "\n",
        "    # Validation (assuming X_val, y_val are in memory)\n",
        "    val_loss = mean_squared_error(y_clean, model.predict(X_clean))\n",
        "    if val_loss < min_val_loss:\n",
        "        min_val_loss = val_loss\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "35m_lmiycAi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d97f232-2d61-44d4-d54d-059bee9d60d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Computation"
      ],
      "metadata": {
        "id": "QeAgw9KcritZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Strategy               | Functionality                                              | Analogy                               | Key Components                                      | Use Cases                                     | Parallelism          | GIL Handling                                       |\n",
        "| ---------------------- | ---------------------------------------------------------- | ------------------------------------- | --------------------------------------------------- | --------------------------------------------- | -------------------- | -------------------------------------------------- |\n",
        "| **Threading**          | Runs multiple tasks concurrently, best for I/O-bound tasks | One waiter serving many tables        | `threading.Thread`, `Lock`                          | Web scraping, file I/O, API calls             | No                   | GIL blocks CPU-bound                               |\n",
        "| **Multiprocessing**    | Runs tasks in separate processes, true parallelism         | Multiple chefs in separate kitchens   | `multiprocessing.Process`, `Pool`, `Queue`          | CPU-bound work, ML training, video processing | Yes                  | Each process has own GIL                           |\n",
        "| **Asyncio**            | Cooperative multitasking for I/O-bound tasks               | One chef juggling many timers         | `async def`, `await`, `asyncio.run`, `gather`       | Web servers, DB queries, async APIs           | No (concurrent only) | Single-threaded, GIL not an issue                  |\n",
        "| **Joblib / Dask**      | High-level parallelism for ML/data                         | Factory line with distributed workers | `joblib.Parallel`, `dask.delayed`, `Dask DataFrame` | Scikit-learn training, big data batch jobs    | Yes                  | Under the hood uses multiprocessing or distributed |\n",
        "| **Cython/Numba**       | Compiles Python to fast machine code                       | Assembling parts using power tools    | `@jit`, `cdef`, `prange`                            | Numeric computation, loops on arrays          | Yes (with config)    | Can release GIL                                    |\n",
        "| **Concurrent.futures** | Simplified interface for threads or processes              | Task manager delegating to teams      | `ThreadPoolExecutor`, `ProcessPoolExecutor`         | Async task execution, simple parallelism      | Thread/Process       | Depends on executor type                           |\n"
      ],
      "metadata": {
        "id": "FZEB1gJVrkyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def io_task():\n",
        "    time.sleep(2)  # Simulates I/O\n",
        "    print(\"Finished I/O\")\n",
        "\n",
        "# Serial\n",
        "io_task()\n",
        "io_task()\n",
        "\n",
        "print(\"Total time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s64V4IizSIn",
        "outputId": "28227893-b988-4d95-cebf-0f97646fcffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished I/O\n",
            "Finished I/O\n",
            "Total time: 4.001073598861694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# multiple threads run in the same process.\n",
        "# Due to GIL, only one thread runs\n",
        "# releases GIL for other thread and then recaptures\n",
        "\n",
        "\n",
        "# Parallel with threads\n",
        "t1 = threading.Thread(target=io_task)\n",
        "t2 = threading.Thread(target=io_task)\n",
        "t1.start()\n",
        "t2.start()\n",
        "t1.join()\n",
        "t2.join()\n",
        "\n",
        "print(\"Total time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXpMsuhvzMof",
        "outputId": "f5ee9209-f7fb-4ae2-e950-0840b92e5aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished I/O\n",
            "Finished I/O\n",
            "Total time: 2.0027577877044678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "import time\n",
        "\n",
        "# separate processes running on different CPU cores\n",
        "# own python interpretor and mempory space\n",
        "\n",
        "\n",
        "def task(name):\n",
        "    print(f\"{name} starting\")\n",
        "    time.sleep(2)\n",
        "    print(f\"{name} done\")\n",
        "\n",
        "p1 = Process(target=task, args=(\"Process-1\",))\n",
        "p2 = Process(target=task, args=(\"Process-2\",))\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV3rz-WVzDOH",
        "outputId": "1fc83da1-f765-4634-90dd-c3579e30c8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process-1 starting\n",
            "Process-2 starting\n",
            "Process-1 done\n",
            "Process-2 done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "# single thread but cooperative\n",
        "# using await #\n",
        "\n",
        "async def cook(item, time_sec):\n",
        "    print(f\"Started cooking {item}\")\n",
        "    await asyncio.sleep(time_sec)  # Simulates waiting (non-blocking)\n",
        "    print(f\"Finished cooking {item}\")\n",
        "\n",
        "async def main():\n",
        "    # Launch all tasks concurrently\n",
        "    await asyncio.gather(\n",
        "        cook(\"Pasta\", 3),\n",
        "        cook(\"Soup\", 2),\n",
        "        cook(\"Steak\", 4),\n",
        "    )\n",
        "\n",
        "#asyncio.run(main())\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lodhfPQzkIu",
        "outputId": "f609c2e5-14a1-470d-8f97-9b439df43d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started cooking Pasta\n",
            "Started cooking Soup\n",
            "Started cooking Steak\n",
            "Finished cooking Soup\n",
            "Finished cooking Pasta\n",
            "Finished cooking Steak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjJaFC7E23W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import threading\n",
        "import multiprocessing\n",
        "from queue import Queue\n",
        "\n",
        "try:\n",
        "    from pyspark.sql import SparkSession\n",
        "    SPARK_AVAILABLE = True\n",
        "except ImportError:\n",
        "    SPARK_AVAILABLE = False\n",
        "\n",
        "\n",
        "def character_counter(batch):\n",
        "    count = 0\n",
        "    for line in batch:\n",
        "        for char in line:\n",
        "            count += 1\n",
        "    print(f\"Processed batch with {count} characters\")\n",
        "\n",
        "\n",
        "class BatchFileProcessor:\n",
        "    def __init__(self, filepath, batch_size=1000):\n",
        "        self.filepath = filepath\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def read_text_in_batches(self, output_queue, filter_fn=None):\n",
        "        with open(self.filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            batch = []\n",
        "            for line in f:\n",
        "                if filter_fn is None or filter_fn(line):\n",
        "                    batch.append(line.rstrip())\n",
        "                if len(batch) == self.batch_size:\n",
        "                    output_queue.put(batch)\n",
        "                    batch = []\n",
        "            if batch:\n",
        "                output_queue.put(batch)\n",
        "        output_queue.put(None)\n",
        "\n",
        "    def read_csv_in_batches(self, output_queue, filter_fn=None, usecols=None):\n",
        "        for chunk in pd.read_csv(self.filepath, chunksize=self.batch_size, usecols=usecols):\n",
        "            if filter_fn:\n",
        "                chunk = chunk[chunk.apply(filter_fn, axis=1)]\n",
        "            lines = chunk.astype(str).values.tolist()\n",
        "            flat_lines = [\" \".join(row) for row in lines]\n",
        "            output_queue.put(flat_lines)\n",
        "        output_queue.put(None)\n",
        "\n",
        "    def read_with_spark(self, filter_expr=None, columns=None):\n",
        "        if not SPARK_AVAILABLE:\n",
        "            raise ImportError(\"PySpark is not installed.\")\n",
        "\n",
        "        spark = SparkSession.builder.getOrCreate()\n",
        "        df = spark.read.csv(self.filepath, header=True, inferSchema=True)\n",
        "        if columns:\n",
        "            df = df.select(columns)\n",
        "        if filter_expr:\n",
        "            df = df.filter(filter_expr)\n",
        "        return df\n",
        "\n",
        "    def process_batches_with_multiprocessing(self, mode=\"text\", **kwargs):\n",
        "        output_queue = Queue()\n",
        "\n",
        "        # define threads\n",
        "        if mode == \"text\":\n",
        "            thread = threading.Thread(target=self.read_text_in_batches, args=(output_queue,), kwargs=kwargs)\n",
        "\n",
        "        elif mode == 'csv':\n",
        "            thread = threading.Thread(target=self.read_csv_in_batches, args=(output_queue,), kwargs=kwargs)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported mode: choose 'text' or 'csv'\")\n",
        "\n",
        "        thread.start()\n",
        "\n",
        "        pool = multiprocessing.Pool()\n",
        "        active = 0\n",
        "        while True:\n",
        "            batch = output_queue.get()\n",
        "            if batch is None:\n",
        "                break\n",
        "            pool.apply_async(character_counter, args=(batch,))\n",
        "            active += 1\n",
        "\n",
        "        thread.join()\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "bfp = BatchFileProcessor('server.log', batch_size=2)\n",
        "bfp.process_batches_with_multiprocessing(mode=\"text\")\n",
        "\n",
        "print(\"Total time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfXuN5BZ2sle",
        "outputId": "bcaa3952-00a3-442f-d4fc-d22a8d0e5f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 98 charactersProcessed batch with 99 characters\n",
            "Processed batch with 104 characters\n",
            "\n",
            "Processed batch with 107 charactersProcessed batch with 111 characters\n",
            "\n",
            "Processed batch with 66 characters\n",
            "Total time: 3196.8767352104187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9wiV1St4meF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priority Queue"
      ],
      "metadata": {
        "id": "I8teB4jyCkCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "import itertools\n",
        "\n",
        "class PrioritizedItem:\n",
        "    def __init__(self, priority, item):\n",
        "        self.priority = priority\n",
        "        self.item = item\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.priority < other.priority\n",
        "\n",
        "class CustomPriorityQueue:\n",
        "    def __init__(self):\n",
        "        self.heap = []\n",
        "        self.__entry_finder = {}  # mapping of items to entries\n",
        "        self.REMOVED = \"<removed-task>\"\n",
        "        self.counter = itertools.count()  # unique sequence count # just a counter\n",
        "\n",
        "    def add(self, item, priority=0):\n",
        "        # already exists\n",
        "        if item in self.__entry_finder:\n",
        "            self.remove(item)\n",
        "\n",
        "\n",
        "        count = next(self.counter) # just a counter\n",
        "        entry = [priority, count, item]\n",
        "        self.__entry_finder[item] = entry\n",
        "        heapq.heappush(self.heap, entry)\n",
        "\n",
        "    def remove(self, item):\n",
        "        # remove from mapper\n",
        "        entry = self.__entry_finder.pop(item)\n",
        "\n",
        "        # label it, lazy delete\n",
        "        entry[-1] = self.REMOVED\n",
        "\n",
        "    def pop(self):\n",
        "        while self.heap:\n",
        "            priority, count, item = heapq.heappop(self.heap)\n",
        "            if item is not self.REMOVED: # check validity\n",
        "                del self.__entry_finder[item]\n",
        "                return item\n",
        "        raise KeyError(\"pop from an empty priority queue\")\n",
        "\n",
        "    def peek(self):\n",
        "        while self.heap:\n",
        "            priority, count, item = self.heap[0]\n",
        "            if item is self.REMOVED: # check validity: # item marked as removed\n",
        "                heapq.heappop(self.heap)\n",
        "            else:\n",
        "                return item\n",
        "        raise KeyError(\"peek from an empty priority queue\")\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        return item in self.__entry_finder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__entry_finder)\n",
        "\n",
        "q = CustomPriorityQueue()\n",
        "q.add('a', 1)\n",
        "q.add('b', 2)\n",
        "q.add('c', 3)\n",
        "q.add('d', 4)\n",
        "\n",
        "q.peek()\n",
        "q.remove('b')\n",
        "q.pop()\n",
        "q.peek()\n",
        "q.remove('c')\n",
        "\n",
        "print(q._CustomPriorityQueue__entry_finder)\n",
        "print(q.heap)\n",
        "q.peek()"
      ],
      "metadata": {
        "id": "ik_SWdW_ClJi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c9fc8ab0-4bf6-4b02-c220-650e873322cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d': [4, 3, 'd']}\n",
            "[[3, 2, '<removed-task>'], [4, 3, 'd']]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_task_scheduler():\n",
        "    tasks = [\n",
        "        (\"Email Sync\", 3),\n",
        "        (\"Video Encoding\", 1),\n",
        "        (\"System Backup\", 2),\n",
        "        (\"Antivirus Scan\", 4),\n",
        "    ]\n",
        "\n",
        "\n",
        "    pq = CustomPriorityQueue()\n",
        "    for task, priority in tasks:\n",
        "        pq.add(task, priority)\n",
        "\n",
        "    print(\"Processing tasks by priority:\")\n",
        "    while len(pq):\n",
        "        print(pq.pop())\n",
        "\n",
        "test_task_scheduler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmQDovkIDMpa",
        "outputId": "9046a901-f10e-4d1a-e3b9-0d4dc0c1400b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing tasks by priority:\n",
            "Video Encoding\n",
            "System Backup\n",
            "Email Sync\n",
            "Antivirus Scan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def visualize_graph(graph_dict):\n",
        "  graph = nx.Graph()\n",
        "  for node, edges in graph_dict.items():\n",
        "    for neighbor, weight in edges:\n",
        "      graph.add_edge(node, neighbor, weight=weight)\n",
        "\n",
        "  pos = nx.spring_layout(graph)  # positions for all nodes\n",
        "  nx.draw(graph, pos, with_labels=True, node_size=700, node_color=\"skyblue\", font_size=10, font_weight='bold', width=2)\n",
        "  edge_labels = nx.get_edge_attributes(graph,'weight')\n",
        "  nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# add start\n",
        "def dijkstra(graph, start):\n",
        "    pq = CustomPriorityQueue()\n",
        "    distances = {node: float('inf') for node in graph}\n",
        "    distances[start] = 0\n",
        "    pq.add(start, 0)\n",
        "\n",
        "    while len(pq):\n",
        "        current = pq.pop()\n",
        "\n",
        "        for neighbor, weight in graph[current]:\n",
        "            new_dist = distances[current] + weight\n",
        "            if new_dist < distances[neighbor]:\n",
        "                distances[neighbor] = new_dist\n",
        "                pq.add(neighbor, new_dist)\n",
        "\n",
        "    return distances\n",
        "\n",
        "def test_dijkstra():\n",
        "    graph = defaultdict(list)\n",
        "    graph['A'].extend([('B', 1), ('C', 4)])\n",
        "    graph['B'].extend([('C', 2), ('D', 5)])\n",
        "    graph['C'].append(('D', 1))\n",
        "    graph['D'] = []\n",
        "\n",
        "    visualize_graph(graph)\n",
        "\n",
        "    distances = dijkstra(graph, 'A')\n",
        "    for node in sorted(distances):\n",
        "        print(f\"Distance from A to {node}: {distances[node]}\")\n",
        "\n",
        "test_dijkstra()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "wW0yaxKtDNJq",
        "outputId": "1e2eb402-38c3-46c0-dcb0-0ecb08a8f96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance from A to A: 0\n",
            "Distance from A to B: 1\n",
            "Distance from A to C: 3\n",
            "Distance from A to D: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Data Structures"
      ],
      "metadata": {
        "id": "YHDeDOYZWIZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://leetcode.com/problems/design-add-and-search-words-data-structure/\n",
        "2. https://leetcode.com/problems/implement-trie-prefix-tree/"
      ],
      "metadata": {
        "id": "fv2aSc0XW7fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_word = False\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert(self, word: str):\n",
        "        node = self.root\n",
        "        for ch in word:\n",
        "            node = node.children.setdefault(ch, TrieNode())\n",
        "        node.is_word = True\n",
        "\n",
        "    def search(self, word: str) -> bool:\n",
        "        node = self._find_node(word)\n",
        "        return node.is_word if node else False\n",
        "\n",
        "    def starts_with(self, prefix: str) -> bool:\n",
        "        return bool(self._find_node(prefix))\n",
        "\n",
        "    def _find_node(self, prefix: str):\n",
        "        node = self.root\n",
        "        for ch in prefix:\n",
        "            node = node.children.get(ch)\n",
        "            if not node:\n",
        "                return None\n",
        "        return node\n",
        "\n",
        "# Test\n",
        "trie = Trie()\n",
        "for word in [\"cat\", \"car\", \"care\", \"dog\"]:\n",
        "    trie.insert(word)\n",
        "print(trie.search(\"car\"))         # True\n",
        "print(trie.starts_with(\"ca\"))     # True\n",
        "print(trie.search(\"cart\"))        # False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgYEz758WJi5",
        "outputId": "40ecd453-7f04-437d-9a94-fb6fe114103c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SuffixTrie:\n",
        "    def __init__(self, text: str):\n",
        "        self.root = {}\n",
        "        self.build(text)\n",
        "\n",
        "    def build(self, text: str):\n",
        "        for i in range(len(text)):\n",
        "\n",
        "            # akways start from the root\n",
        "            node = self.root\n",
        "            suffix = text[i:] # suffix starting at i\n",
        "\n",
        "            for ch in suffix:\n",
        "                node = node.setdefault(ch, {})\n",
        "\n",
        "            # now, node is the last character of this suffix starting at i\n",
        "            # mark it terminal, i marks start of this suffix\n",
        "            node[\"$\"] = i\n",
        "\n",
        "    def has_substring(self, pattern: str) -> bool:\n",
        "        node = self.root\n",
        "        for ch in pattern:\n",
        "            if ch not in node:\n",
        "                return False\n",
        "            node = node[ch]\n",
        "        return True\n",
        "\n",
        "# Test\n",
        "s_trie = SuffixTrie(\"banana\")\n",
        "print(s_trie.has_substring(\"ana\"))  # True\n",
        "print(s_trie.has_substring(\"nana\")) # True\n",
        "print(s_trie.has_substring(\"apple\"))# False\n"
      ],
      "metadata": {
        "id": "O1kmZ-FnXt8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "class InvertedIndex:\n",
        "    def __init__(self):\n",
        "        self.index = defaultdict(set)\n",
        "\n",
        "    def add_document(self, doc_id: int, text: str):\n",
        "        for word in text.lower().split():\n",
        "            self.index[word].add(doc_id)\n",
        "\n",
        "    def search(self, word: str):\n",
        "        return self.index.get(word.lower(), set())\n",
        "\n",
        "# Test\n",
        "inv_index = InvertedIndex()\n",
        "docs = {\n",
        "    1: \"cat dog elephant\",\n",
        "    2: \"dog lion tiger\",\n",
        "    3: \"elephant giraffe cat\"\n",
        "}\n",
        "for doc_id, content in docs.items():\n",
        "    inv_index.add_document(doc_id, content)\n",
        "\n",
        "print(inv_index.search(\"cat\"))     # {1, 3}\n",
        "print(inv_index.search(\"dog\"))     # {1, 2}\n",
        "print(inv_index.search(\"lion\"))    # {2}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4iw5HHbX4Kw",
        "outputId": "22a671ff-1190-4088-8167-29f36c5de5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 3}\n",
            "{1, 2}\n",
            "{2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "class SearchEngine:\n",
        "    def __init__(self):\n",
        "        self.doc_freq = defaultdict(set)\n",
        "        self.term_freq = defaultdict(lambda: defaultdict(int))\n",
        "        self.num_docs = 0\n",
        "\n",
        "    def add_document(self, doc_id, text):\n",
        "        self.num_docs += 1\n",
        "        words = text.lower().split()\n",
        "        seen = set()\n",
        "        for word in words:\n",
        "            self.term_freq[doc_id][word] += 1\n",
        "            self.doc_freq[word].add(doc_id)\n",
        "\n",
        "    def tf_idf(self, word, doc_id):\n",
        "        tf = self.term_freq[doc_id].get(word, 0)\n",
        "        df = len(self.doc_freq[word])\n",
        "        idf = math.log((1 + self.num_docs) / (1 + df)) + 1\n",
        "        return tf * idf\n",
        "\n",
        "    def boolean_search(self, query_words):\n",
        "        result = None\n",
        "        for word in query_words:\n",
        "            docs = self.doc_freq.get(word.lower(), set())\n",
        "            result = docs if result is None else result & docs\n",
        "        return result\n",
        "\n",
        "# Test\n",
        "se = SearchEngine()\n",
        "se.add_document(1, \"cat dog elephant\")\n",
        "se.add_document(2, \"dog tiger lion\")\n",
        "se.add_document(3, \"elephant giraffe cat\")\n",
        "\n",
        "print(se.boolean_search([\"cat\", \"elephant\"])) # {1, 3}\n",
        "print(se.tf_idf(\"cat\", 1))  # TF-IDF score for \"cat\" in doc 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaZl3XvbEVWQ",
        "outputId": "081e8283-4854-430a-f0d0-6624c998b825"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 3}\n",
            "1.2876820724517808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Structure          | Use Case                                 | Strength                     | Limitation                  |\n",
        "| ------------------ | ---------------------------------------- | ---------------------------- | --------------------------- |\n",
        "| **Trie**           | Autocomplete, prefix filtering           | Fast prefix search (O(L))    | Costly on memory            |\n",
        "| **Suffix Trie**    | Substring search, DNA/text pattern match | Fast substring search        | Space-heavy, not compressed |\n",
        "| **Inverted Index** | Full-text search in documents            | Scalable & fast for keywords | Not ideal for substring     |\n"
      ],
      "metadata": {
        "id": "p8bprYNoYWV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RadixNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_word = False\n",
        "\n",
        "class RadixTrie:\n",
        "    def __init__(self):\n",
        "        self.root = RadixNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        while word:\n",
        "            for key in node.children:\n",
        "                i = 0\n",
        "                while i < len(key) and i < len(word) and key[i] == word[i]:\n",
        "                    i += 1\n",
        "                if i > 0:\n",
        "                    if i == len(key):\n",
        "                        word = word[i:]\n",
        "                        node = node.children[key]\n",
        "                        break\n",
        "                    else:\n",
        "                        existing_child = node.children.pop(key)\n",
        "                        node.children[key[:i]] = RadixNode()\n",
        "                        node.children[key[:i]].children[key[i:]] = existing_child\n",
        "                        node = node.children[key[:i]]\n",
        "                        word = word[i:]\n",
        "                        break\n",
        "            else:\n",
        "                node.children[word] = RadixNode()\n",
        "                node.children[word].is_word = True\n",
        "                return\n",
        "\n",
        "    def search(self, word):\n",
        "        node = self.root\n",
        "        while word:\n",
        "            for key in node.children:\n",
        "                if word.startswith(key):\n",
        "                    word = word[len(key):]\n",
        "                    node = node.children[key]\n",
        "                    break\n",
        "            else:\n",
        "                return False\n",
        "        return node.is_word\n",
        "\n",
        "# Test\n",
        "rt = RadixTrie()\n",
        "rt.insert(\"cat\")\n",
        "rt.insert(\"carpet\")\n",
        "print(rt.search(\"cat\"))      # True\n",
        "print(rt.search(\"car\"))      # False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3tNRrwUYJ_b",
        "outputId": "3b3267d8-13ac-41b1-c737-7f00984266a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SuffixTreeNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "\n",
        "class SuffixTree:\n",
        "    def __init__(self, text):\n",
        "        self.root = SuffixTreeNode()\n",
        "        self.text = text\n",
        "        self._build()\n",
        "\n",
        "    def _build(self):\n",
        "        for i in range(len(self.text)):\n",
        "            current = self.root\n",
        "\n",
        "            # suffix start at i\n",
        "            suffix = self.text[i:]\n",
        "\n",
        "            while suffix:\n",
        "                for edge in current.children:\n",
        "                    if suffix.startswith(edge[0]):\n",
        "                        suffix = suffix[len(edge[0]):]\n",
        "                        current = edge[1]\n",
        "                        break\n",
        "                else: # no suffix that starts with edge\n",
        "                    new_node = SuffixTreeNode()\n",
        "                    current.children[(suffix, new_node)] = new_node\n",
        "                    break\n",
        "\n",
        "    def has_substring(self, pattern):\n",
        "        node = self.root\n",
        "        i = 0\n",
        "        while i < len(pattern):\n",
        "            for (edge, child) in node.children:\n",
        "                if pattern[i:].startswith(edge):\n",
        "                    i += len(edge)\n",
        "                    node = child\n",
        "                    break\n",
        "            else:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "# Test\n",
        "st = SuffixTree(\"banana$\")\n",
        "print(st.has_substring(\"ana\"))  # True\n",
        "print(st.has_substring(\"nana\")) # True\n",
        "print(st.has_substring(\"apple\"))# False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OncfLU8xZTQD",
        "outputId": "6eef447d-40c7-41c6-d7b2-3edaab9b8bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    }
  ]
}